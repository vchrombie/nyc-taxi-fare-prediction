{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34d406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc4d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:36:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-vt2182:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1c7c271b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "conf.set('spark.ui.proxyBase', '/user/' + os.environ['JUPYTERHUB_USER'] + '/proxy/4040')\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b316ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"vt2182\"\n",
    "password = \"vt2182\"\n",
    "host = \"mongo-csgy-6513-spring.db\"\n",
    "auth_database = \"vt2182\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fee785",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_conn_str = f\"mongodb://{username}:{password}@{host}/{auth_database}\"\n",
    "client = MongoClient(mongo_conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f705480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['mongo-csgy-6513-spring.db:27017'], document_class=dict, tz_aware=False, connect=True), 'vt2182')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client[auth_database]\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a23fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_raw']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01515602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd65682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48874e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f07c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the collection\n",
    "collection = db['yellow_tripdata_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff62fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from MongoDB, excluding the _id field\n",
    "data = list(collection.find({}, {'_id': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be2da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of dictionaries to pandas DataFrame\n",
    "pandas_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192f4746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcfc7ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:37:03 WARN TaskSetManager: Stage 0 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 120000 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "print(\"The data contains {} rows.\".format(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01348e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ecc75bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ffd7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:37:10 WARN TaskSetManager: Stage 3 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2022, 12, 3, 19, 14, 47), tpep_dropoff_datetime=datetime.datetime(2022, 12, 3, 19, 31, 51), passenger_count=1.0, trip_distance=3.37, RatecodeID=1.0, store_and_fwd_flag='N', PULocationID=143, DOLocationID=152, payment_type=1, fare_amount=13.5, extra=0.5, mta_tax=0.5, tip_amount=3.46, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=20.76, congestion_surcharge=2.5, airport_fee=0.0, __index_level_0__=375653)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c6e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:37:10 WARN TaskSetManager: Stage 4 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-03 19:14:47</td>\n",
       "      <td>2022-12-03 19:31:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>13.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>375653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-01 11:55:12</td>\n",
       "      <td>2022-12-01 12:18:01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-12 15:54:24</td>\n",
       "      <td>2022-12-12 15:59:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>7.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1402168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-20 05:34:23</td>\n",
       "      <td>2022-12-20 06:14:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>N</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2262245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-23 22:03:11</td>\n",
       "      <td>2022-12-23 22:28:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>164</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>31.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3383941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2022-12-03 19:14:47   2022-12-03 19:31:51              1.0   \n",
       "1         2  2022-12-01 11:55:12   2022-12-01 12:18:01              6.0   \n",
       "2         1  2022-12-12 15:54:24   2022-12-12 15:59:52              1.0   \n",
       "3         1  2022-12-20 05:34:23   2022-12-20 06:14:12              1.0   \n",
       "4         2  2022-12-23 22:03:11   2022-12-23 22:28:44              NaN   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.37         1.0                  N           143           152   \n",
       "1           1.00         1.0                  N           100           230   \n",
       "2           1.90         1.0                  N           236            74   \n",
       "3           0.10        99.0                  N           242           242   \n",
       "4           6.53         NaN               None           164            61   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1        13.50    0.5      0.5        3.46           0.0   \n",
       "1             2        13.50    1.0      0.5        0.00           0.0   \n",
       "2             1         7.50    3.0      0.5        2.25           0.0   \n",
       "3             1        21.50    0.0      0.5        0.00           0.0   \n",
       "4             0        31.83    0.0      0.5        3.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    0.3         20.76                   2.5          0.0   \n",
       "1                    0.3         17.80                   2.5          0.0   \n",
       "2                    0.3         13.55                   2.5          0.0   \n",
       "3                    1.0         23.00                   0.0          0.0   \n",
       "4                    1.0         38.83                   NaN          NaN   \n",
       "\n",
       "   __index_level_0__  \n",
       "0             375653  \n",
       "1              71522  \n",
       "2            1402168  \n",
       "3            2262245  \n",
       "4            3383941  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef65920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f38ecd6c",
   "metadata": {},
   "source": [
    "Given the schema of the data, here are some preprocessing steps:\n",
    "\n",
    "1. Removing unnecessary columns\n",
    "2. Handling missing values\n",
    "3. Creating new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abcdf1",
   "metadata": {},
   "source": [
    "## Removing unnecessary columns\n",
    "\n",
    "If there are any columns that are not relevant to predicting taxi demand, we can remove them to simplify the data and speed up the computations. For example, the column __index_level_0__ might not be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adccd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['__index_level_0__']\n",
    "df = df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c2e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db548388",
   "metadata": {},
   "source": [
    "## Handling missing values\n",
    "\n",
    "If there are any missing values in the data, we can drop the rows or columns that contain them or need to fill them in, depending on how many there are and their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a212e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:38:23 WARN TaskSetManager: Stage 5 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       0|           4168|            0|      4168|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|                4168|       4168|\n",
      "+--------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n",
      "23/05/09 11:38:26 WARN TaskSetManager: Stage 8 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|store_and_fwd_flag|\n",
      "+--------------------+---------------------+------------------+\n",
      "|                   0|                    0|              4168|\n",
      "+--------------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "# Check for missing values in numerical columns\n",
    "numerical_columns = ['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in numerical_columns]).show()\n",
    "\n",
    "# Check for missing values in non-numerical columns\n",
    "non_numerical_columns = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'store_and_fwd_flag']\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in non_numerical_columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff24c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5748d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:38:29 WARN TaskSetManager: Stage 11 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115832"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13144013",
   "metadata": {},
   "source": [
    "Alternatively, you can fill missing values with specific values\n",
    "- replace missing numerical values with the median\n",
    "- replace missing categorical values with the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52d1e9",
   "metadata": {},
   "source": [
    "## Creating new features\n",
    "\n",
    "We can create new features that might be more predictive of taxi demand than the existing ones. For example, we can extract the hour of day, day of week, or month from the `tpep_pickup_datetime` and `tpep_dropoff_datetime` columns, which might be important for predicting demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4bacb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour, dayofweek\n",
    "\n",
    "# Create new features\n",
    "df = df.withColumn('pickup_year', year(df['tpep_pickup_datetime']))\n",
    "df = df.withColumn('pickup_month', month(df['tpep_pickup_datetime']))\n",
    "df = df.withColumn('pickup_day', dayofmonth(df['tpep_pickup_datetime']))\n",
    "df = df.withColumn('pickup_hour', hour(df['tpep_pickup_datetime']))\n",
    "df = df.withColumn('pickup_day_of_week', dayofweek(df['tpep_pickup_datetime']))\n",
    "\n",
    "df = df.withColumn('dropoff_year', year(df['tpep_dropoff_datetime']))\n",
    "df = df.withColumn('dropoff_month', month(df['tpep_dropoff_datetime']))\n",
    "df = df.withColumn('dropoff_day', dayofmonth(df['tpep_dropoff_datetime']))\n",
    "df = df.withColumn('dropoff_hour', hour(df['tpep_dropoff_datetime']))\n",
    "df = df.withColumn('dropoff_day_of_week', dayofweek(df['tpep_dropoff_datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ae9dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- pickup_year: integer (nullable = true)\n",
      " |-- pickup_month: integer (nullable = true)\n",
      " |-- pickup_day: integer (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- pickup_day_of_week: integer (nullable = true)\n",
      " |-- dropoff_year: integer (nullable = true)\n",
      " |-- dropoff_month: integer (nullable = true)\n",
      " |-- dropoff_day: integer (nullable = true)\n",
      " |-- dropoff_hour: integer (nullable = true)\n",
      " |-- dropoff_day_of_week: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51e9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "700b608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:38:37 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/05/09 11:38:38 WARN TaskSetManager: Stage 14 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_year</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_day_of_week</th>\n",
       "      <th>dropoff_year</th>\n",
       "      <th>dropoff_month</th>\n",
       "      <th>dropoff_day</th>\n",
       "      <th>dropoff_hour</th>\n",
       "      <th>dropoff_day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-03 19:14:47</td>\n",
       "      <td>2022-12-03 19:31:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-01 11:55:12</td>\n",
       "      <td>2022-12-01 12:18:01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-12 15:54:24</td>\n",
       "      <td>2022-12-12 15:59:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-20 05:34:23</td>\n",
       "      <td>2022-12-20 06:14:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>N</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-10 03:59:40</td>\n",
       "      <td>2022-12-10 04:07:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>24</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2022-12-03 19:14:47   2022-12-03 19:31:51              1.0   \n",
       "1         2  2022-12-01 11:55:12   2022-12-01 12:18:01              6.0   \n",
       "2         1  2022-12-12 15:54:24   2022-12-12 15:59:52              1.0   \n",
       "3         1  2022-12-20 05:34:23   2022-12-20 06:14:12              1.0   \n",
       "4         2  2022-12-10 03:59:40   2022-12-10 04:07:27              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.37         1.0                  N           143           152   \n",
       "1           1.00         1.0                  N           100           230   \n",
       "2           1.90         1.0                  N           236            74   \n",
       "3           0.10        99.0                  N           242           242   \n",
       "4           1.99         1.0                  N            24           236   \n",
       "\n",
       "   payment_type  ...  pickup_year  pickup_month  pickup_day  pickup_hour  \\\n",
       "0             1  ...         2022            12           3           19   \n",
       "1             2  ...         2022            12           1           11   \n",
       "2             1  ...         2022            12          12           15   \n",
       "3             1  ...         2022            12          20            5   \n",
       "4             1  ...         2022            12          10            3   \n",
       "\n",
       "   pickup_day_of_week  dropoff_year  dropoff_month  dropoff_day  dropoff_hour  \\\n",
       "0                   7          2022             12            3            19   \n",
       "1                   5          2022             12            1            12   \n",
       "2                   2          2022             12           12            15   \n",
       "3                   3          2022             12           20             6   \n",
       "4                   7          2022             12           10             4   \n",
       "\n",
       "   dropoff_day_of_week  \n",
       "0                    7  \n",
       "1                    5  \n",
       "2                    2  \n",
       "3                    3  \n",
       "4                    7  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef95a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4398f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the collection\n",
    "collection = db['yellow_tripdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5963c707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:38:42 WARN TaskSetManager: Stage 15 contains a task of very large size (8505 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    }
   ],
   "source": [
    "# Convert the PySpark DataFrame to a Pandas DataFrame\n",
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdc6b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pandas DataFrame to a dictionary\n",
    "data_dict = pandas_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb73d628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f1c325bb310>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert the dictionary into MongoDB\n",
    "collection.insert_many(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd878e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
